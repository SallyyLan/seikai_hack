{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YJ97HnqchE2p"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **code for both**"
      ],
      "metadata": {
        "id": "YJ97HnqchE2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass"
      ],
      "metadata": {
        "id": "mg9QfIKHer0H"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **gemini-2.5-flash to transcribe exam**"
      ],
      "metadata": {
        "id": "-d7Izvs6eYCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from tkinter import Tk, filedialog\n",
        "\n",
        "# =============================\n",
        "# 1. Ask for API key securely\n",
        "# =============================\n",
        "if not os.getenv(\"GEMINI_API_KEY\"):\n",
        "    os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyC_uYzO4pxlE4E4E6jbWRRO2OOIhgHWiEU\"\n",
        "\n",
        "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# =============================\n",
        "# 2. System Prompt\n",
        "# =============================\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are an OCR and transcription model for handwritten or printed academic exam work.\n",
        "Your ONLY task is to convert the student's work from one or more provided images into a continuous text transcript, following the exact formatting rules below.\n",
        "Do NOT assess correctness or provide feedback.\n",
        "Do NOT add extra commentary.\n",
        "Do NOT translate text.\n",
        "Do NOT add page breaks.\n",
        "\n",
        "====================\n",
        "TRANSCRIPTION RULES\n",
        "====================\n",
        "\n",
        "1. Problem detection:\n",
        "   - Problems start with \"Q<number>)\".\n",
        "   - If a problem has subparts, write them as \"Q<number>) a.\" (or b., c., etc.).\n",
        "   - Assume problems start with a visible label in the student's work.\n",
        "   - Merge all pages/images into one continuous transcript.\n",
        "\n",
        "2. Step formatting:\n",
        "   - Use \"-\" for bullet points.\n",
        "   - Each bullet may contain:\n",
        "       • Words in original language (do not translate).\n",
        "       • Inline LaTeX for math and equations.\n",
        "       • Mixed words and math are allowed.\n",
        "   - Inline LaTeX must be enclosed in single dollar signs: `$...$`\n",
        "   - Multi-line derivations: each line is its own bullet.\n",
        "\n",
        "3. Diagrams and figures:\n",
        "   - If identifiable: `[diagram: <best-guess label>]`\n",
        "       Example: `[diagram: graph (rational function)]`\n",
        "   - If unsure: `[diagram?]`\n",
        "   - Never describe the diagram in full, just label it.\n",
        "\n",
        "4. Uncertain handwriting:\n",
        "   - If text/equation is uncertain, enclose it in:\n",
        "       `[uncertain: text](confidence)`\n",
        "       Example: `[uncertain: boundary was $0$ to $l$?](0.6)`\n",
        "   - Confidence is one decimal between 0.0 and 1.0.\n",
        "\n",
        "5. Crossed-out work:\n",
        "   - Exclude all crossed-out content completely.\n",
        "\n",
        "6. Mixed languages:\n",
        "   - Keep text exactly as written, including all punctuation and characters.\n",
        "   - Keep math notation as LaTeX even if surrounding text is in another language.\n",
        "\n",
        "7. Fallbacks:\n",
        "   - If an equation is unreadable, attempt best guess and mark it as uncertain.\n",
        "   - If no problems detected, output: `No content detected`.\n",
        "\n",
        "8. Output:\n",
        "   - Return ONLY the transcription text in plain text, no JSON, no Markdown fences, no commentary.\n",
        "   - Maintain exact sequence of problems and steps as in the student's work.\n",
        "\n",
        "====================\n",
        "EXAMPLES\n",
        "====================\n",
        "\n",
        "Example 1:\n",
        "Q1)\n",
        "- Given $f(x)=\\frac{x^2+5}{x-3}$, simplify.\n",
        "- Multiply numerator and denominator by $(x-3)$.\n",
        "- $f(x)=\\frac{x^2+5}{x-3}$\n",
        "- [diagram: graph (rational function)]\n",
        "\n",
        "Q2) a.\n",
        "- Solve for $x$: $2x+5=15$.\n",
        "- Subtract $5$: $2x=10$.\n",
        "- Divide by $2$: $x=5$.\n",
        "\n",
        "Example 2:\n",
        "Q3)\n",
        "- Compute $\\int_0^1 x^2\\,dx$.\n",
        "- Antiderivative: $\\frac{x^3}{3}\\Big|_0^1$.\n",
        "- Result: $\\frac{1}{3}$.\n",
        "- [uncertain: boundary was $0$ to $l$?](0.6)\n",
        "\n",
        "Q4) b.\n",
        "- La velocidad es $v(t) = 3t^2 + 2$.\n",
        "- Calcular desplazamiento: $\\int_0^5 3t^2 + 2 \\, dt$.\n",
        "\n",
        "====================\n",
        "END OF RULES\n",
        "====================\n",
        "\n",
        "Your job: read the student's work from all provided images, follow these rules exactly, and output the final continuous transcript.\n",
        "\"\"\"\n",
        "\n",
        "# =============================\n",
        "# 3. Upload file\n",
        "# =============================\n",
        "def upload_file(path: str):\n",
        "    \"\"\"Uploads PDF/JPG/PNG to Gemini Files API.\"\"\"\n",
        "    return client.files.upload(file_path=path)\n",
        "\n",
        "# =============================\n",
        "# 4. Build request parts\n",
        "# =============================\n",
        "def parts_with_exam(prompt_text: str, exam):\n",
        "    \"\"\"Builds Gemini message parts with text and file(s).\"\"\"\n",
        "    parts = [{\"text\": prompt_text}]\n",
        "    if isinstance(exam, list):\n",
        "        for f in exam:\n",
        "            parts.append({\"file_data\": {\"file_uri\": f.uri, \"mime_type\": f.mime_type}})\n",
        "    else:\n",
        "        parts.append({\"file_data\": {\"file_uri\": exam.uri, \"mime_type\": exam.mime_type}})\n",
        "    return parts\n",
        "\n",
        "# =============================\n",
        "# 5. Main transcription function\n",
        "# =============================\n",
        "def transcribe_exam(file_paths):\n",
        "    \"\"\"Takes one or more file paths, uploads them, sends to Gemini, and returns transcript.\"\"\"\n",
        "    # Upload\n",
        "    if isinstance(file_paths, str):\n",
        "        exam_files = upload_file(file_paths)\n",
        "    else:\n",
        "        exam_files = [upload_file(p) for p in file_paths]\n",
        "\n",
        "    # Request\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",\n",
        "        contents=[\n",
        "            {\"role\": \"system\", \"parts\": [{\"text\": SYSTEM_PROMPT}]},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": parts_with_exam(\n",
        "                    \"Read all pages/images and output ONLY the transcription text per the rules.\",\n",
        "                    exam_files\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    )\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "dWY1zyW1daWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    Tk().withdraw()  # Hide root window\n",
        "    selected_file = filedialog.askopenfilename(\n",
        "        title=\"Select Exam PDF or Image\",\n",
        "        filetypes=[\n",
        "            (\"PDF files\", \"*.pdf\"),\n",
        "            (\"Image files\", \"*.jpg *.jpeg *.png\"),\n",
        "            (\"All files\", \"*.*\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    if not selected_file:\n",
        "        print(\"No file selected. Exiting...\")\n",
        "    else:\n",
        "        transcript = transcribe_exam(selected_file)\n",
        "        print(\"\\n--- Transcript ---\\n\")\n",
        "        print(transcript)\n",
        "\n",
        "#------------------WILL FAIL IF USING COLAB BECAUSE ONE IMPORT REQUIRES GUI------------------#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "gC9huaN0h3xv",
        "outputId": "08015c46-3021-4236-d8ed-be6f9c85fe65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "no display name and no $DISPLAY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3565411424.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Hide root window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     selected_file = filedialog.askopenfilename(\n\u001b[1;32m      4\u001b[0m         \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Select Exam PDF or Image\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         filetypes=[\n",
            "\u001b[0;32m/usr/lib/python3.11/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **gpt-oss-20b to classify the work**"
      ],
      "metadata": {
        "id": "37GFyuW0eJKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "x64WRE6MICor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU openai"
      ],
      "metadata": {
        "id": "BXicpfyuJA3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        ")"
      ],
      "metadata": {
        "id": "3BPXMzShJLqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YSZQPFWHdKl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "prompt = \"<Fill in later>: \" + transcript\n",
        "\n",
        "response = client.responses.create(\n",
        "  model=\"openai/gpt-oss-20b\",\n",
        "  input=[prompt],\n",
        "  reasoning={\"effort\" : \"high\"},\n",
        "  max_output_tokens=4096,\n",
        "  top_p=0.7,\n",
        "  temperature=0.6,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "reasoning_done = False\n",
        "for chunk in response:\n",
        "    if chunk.type == \"response.output_text.delta\":\n",
        "        print(chunk.delta, end=\"\")\n"
      ]
    }
  ]
}